import { downloadBlob } from "./download.js";

/**
 * startCapture() retorna { stop, stopped }:
 *  - stop(): pede para parar (equivale ao bot칚o "Parar")
 *  - stopped: Promise que resolve quando a grava칞칚o terminou de verdade
 */
export async function startCapture() {
  // 游댍 Bloqueio expl칤cito para Firefox (sem suporte a 치udio do sistema via getDisplayMedia)
  const isFirefox = navigator.userAgent.toLowerCase().includes("firefox");
  if (isFirefox) {
    alert("丘멆잺 Este navegador (Firefox) n칚o 칠 compat칤vel com captura do 치udio do sistema. Use Chrome ou Edge para gravar o 치udio da tela/aba.");
    throw new Error("Navegador n칚o compat칤vel com 치udio do sistema.");
  }

  // 1) Captura da tela/aba COM 치udio do sistema (Chrome/Edge)
  const displayStream = await navigator.mediaDevices.getDisplayMedia({
    // precisa pedir v칤deo para abrir o prompt; limitamos o custo
    video: { frameRate: 1 },
    audio: true
  });

  // economiza: desabilita v칤deo (n칚o usamos imagem)
  const videoTrack = displayStream.getVideoTracks()[0];
  if (videoTrack) videoTrack.enabled = false;

  const sysTrack = displayStream.getAudioTracks()[0];
  if (!sysTrack) {
    displayStream.getTracks().forEach(t => t.stop());
    throw new Error("Sem 치udio da tela/aba (marque 'Compartilhar 치udio').");
  }

  // 2) Microfone
  const micStream = await navigator.mediaDevices.getUserMedia({
    audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: true },
    video: false
  });
  const micTrack = micStream.getAudioTracks()[0];
  if (!micTrack) {
    micStream.getTracks().forEach(t => t.stop());
    displayStream.getTracks().forEach(t => t.stop());
    throw new Error("Microfone n칚o dispon칤vel.");
  }

  // --- MIX e downmix para MONO ---
  const ctx = new AudioContext();
  const dest = ctx.createMediaStreamDestination();

  const sysSource = ctx.createMediaStreamSource(new MediaStream([sysTrack]));
  const micSource = ctx.createMediaStreamSource(new MediaStream([micTrack]));

  const sysGain = ctx.createGain(); sysGain.gain.value = 1.0;
  const micGain = ctx.createGain(); micGain.gain.value = 1.0;

  const merger = ctx.createChannelMerger(1); // mono
  sysSource.connect(sysGain).connect(merger);
  micSource.connect(micGain).connect(merger);
  merger.connect(dest);

  const mixedStream = dest.stream;

  const mime = MediaRecorder.isTypeSupported("audio/webm;codecs=opus")
    ? "audio/webm;codecs=opus"
    : (MediaRecorder.isTypeSupported("audio/webm") ? "audio/webm" : "");

  const rec = new MediaRecorder(mixedStream, mime ? { mimeType: mime } : undefined);
  const chunks = [];

  let resolveStopped;
  const stopped = new Promise(res => (resolveStopped = res));
  let stopping = false;

  const cleanupAndResolve = () => {
    try {
      const blob = new Blob(chunks, { type: mime || "audio/webm" });
      if (blob.size) downloadBlob(blob, "EuGravoBot");
    } catch {}
    try { displayStream.getTracks().forEach(t => t.stop()); } catch {}
    try { micStream.getTracks().forEach(t => t.stop()); } catch {}
    try { ctx.close(); } catch {}
    resolveStopped?.();
  };

  rec.ondataavailable = e => { if (e.data && e.data.size) chunks.push(e.data); };
  rec.onstop = cleanupAndResolve;

  // Se o usu치rio parar pelo navegador, finalize tamb칠m
  const finalizeIfNeeded = () => {
    if (!stopping && rec.state !== "inactive") {
      stopping = true;
      rec.stop();
    }
  };
  if (videoTrack) videoTrack.addEventListener("ended", finalizeIfNeeded);
  if (sysTrack) {
    sysTrack.addEventListener("ended", finalizeIfNeeded);
    sysTrack.addEventListener("inactive", finalizeIfNeeded);
  }

  rec.start(1000);

  // fun칞칚o p칰blica para o bot칚o "Parar"
  const stop = () => {
    if (!stopping && rec.state !== "inactive") {
      stopping = true;
      rec.stop();
    }
    return stopped; // permite await no chamador
  };

  return { stop, stopped };
}

// compat com c칩digo antigo (se ainda for usado)
export async function stopCapture(handle) {
  if (handle?.stop) return handle.stop();
}
